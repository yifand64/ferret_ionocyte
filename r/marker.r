

library(Matrix)


get_controls <- function(counts, gene.list, verbose=F, control.genes.per.gene=10)
{
	# Itay: "Such scores are inevitably correlated with cell complexity so to avoid 
	# that I subtract a "control" score which is generated by averaging over a control 
	# gene set. Control gene sets are chosen to contain 100 times more genes than the 
	# real gene set (analogous to averaging over 100 control sets of similar size) and 
	# to have the same distribution of population/bulk - based expression levels as the 
	# real gene set, such that they are expected to have the same number of "zeros" and 
	# to eliminate the correlation with complexity."
	# ---------------------------------------------------------------------------------
	# Going to find control points by finding the closest genes in terms of expression level and % of the time we observe it
	if(verbose){info(sprintf("Finding %s background genes based on similarity to given gene set [%s genes]", 
		control.genes.per.gene*length(gene.list), length(gene.list)))}
	info("Summarizing data")
	summary = data.frame(gene=row.names(counts), mean.expr = Matrix::rowMeans(counts), fract.zero = Matrix::rowMeans(counts==0), stringsAsFactors = F)
	#summary = data.frame(gene=row.names(counts), mean.expr = apply(counts,1,mean), fract.zero = apply(counts==0,1,mean), stringsAsFactors = F)
	summary$mean.expr.s = scale(summary$mean.expr)
	summary$fract.zero.s = scale(summary$fract.zero)
	actual.genes = summary[summary$gene %in% gene.list,]
	background.genes = summary[!summary$gene %in% gene.list,]

	#find the 10 closest genes to each cell cycle marker gene and add them to the lists of control genes
	get_closest_genes <- function(i)
	{
		background.genes$dist = sqrt((background.genes$mean.expr.s - actual.genes$mean.expr.s[i])^2 + 
			(background.genes$fract.zero.s - actual.genes$fract.zero.s[i])^2)
		ordered = background.genes$gene[order(background.genes$dist)]
		ordered = ordered[!ordered %in% controls] # don't take genes that already appear in the list 
		closest = head(ordered, n=control.genes.per.gene)
		return(closest)
	}
	controls = c();
	
	for (i in 1:length(gene.list)){
		#info(sprintf("Finding %s control genes for %s", control.genes.per.gene, gene.list[i]))
		closest = get_closest_genes(i)
		#info(sprintf("Found %s: ", length(closest)))
		controls = unique(c(controls, closest))
	}
	
	if(verbose){info(sprintf("Control gene selection complete. %s genes found.", length(controls)))}
	#print(controls)
	return(controls)
}


# arg1 is a normalised counts matrix.
# arg2 is a dataframe of gene lists, named with colnames
# note that the Matrix:: calls are for compability with sparse matrices
### FUNCTION NEEDS TO BE UPDATED. very slow.
score.cells <- function(counts, gene.lists, quality.scores=NULL,
	do.norm=T,
	verbose=T,
	control.genes.per.gene=10,
	log =F, 
	n.cores=1,
	max.length=0, # clip longer gene lists. assumes gene lists are ranked, and will try to take the 'top' n
	remove.non.expressed.genes=T)
{
	rval = NULL
	if(verbose){cat(sprintf("Scoring %i samples based on their expression of %i gene lists..\n", ncol(counts), ncol(gene.lists)))}
	for (i in 1:length(gene.lists) ) {
		score.name = names(gene.lists)[i]
		if(verbose)
		{
			cat("\n")
			info(sprintf("Gene list %s of %s -- %s", i, length(gene.lists), score.name))
		}
		genes = as.character(unname(unlist(gene.lists[[score.name]])))
		len.before = length(genes)
		#genes = as.data.frame(apply(genes,2,function(x)gsub('\\s+', '',x))) #if data frame, not using this now
		genes = gsub(" ", "", genes, fixed = TRUE) # god help you if there's spaces
		genes.non.na = which(genes != "NA")
		genes = genes[genes.non.na]
		na.rmved = len.before-length(genes)
		if(na.rmved>0)
		{
			if(verbose){info(sprintf("Removed %s NAs",na.rmved))}
		}else
		{
			if(verbose){info("No NAs in gene list")}
		}
		## See which genes are present
		found.genes.indices = which(as.character(toupper(rownames(counts))) %in% as.character(toupper(genes)))
		found.genes = as.character(genes)[as.character(toupper(genes)) %in%  as.character(toupper(rownames(counts)))]
		counts.of.genes = counts[found.genes.indices, ]
		print(dim(counts.of.genes))
		print(typeof(counts.of.genes))
		if(nrow(counts.of.genes)==0){error(sprintf("Found %s signature genes in the counts table! Skipping", nrow(counts.of.genes)))}
		else{
				if(verbose){info(sprintf("Found %s signature genes in the counts table", nrow(counts.of.genes)))}
			## see which genes are expressed
			if(remove.non.expressed.genes)
			{
				zero = which(Matrix::rowSums(counts.of.genes) == 0)
				zero.genes = paste(rownames(counts)[zero], collapse=",")
				if(length(zero) > 0)
				{
					warn(sprintf("Removed %s -- \n they are not expressed at all ", zero.genes))
				}
				nonzero = which(Matrix::rowSums(counts.of.genes) >0 )
				counts.of.genes = counts.of.genes[nonzero,]
				found.genes = as.character(found.genes)[as.character(toupper(found.genes)) %in% as.character(toupper(rownames(counts.of.genes)))]
			}
			## Set the appropriate number of genes, preserving rank order.
			if(max.length > 0)
			{
				if(length(found.genes) > max.length){
					found.genes = found.genes[1:max.length]
				}else{
					warn(sprintf("Could not trim to %s genes, there are only %s present and expressed!", max.length, length(found.genes)))
				}
			}
			## Display info saying which genes are not present
			not.found = which(! factor(toupper(genes)) %in% factor(toupper(rownames(counts))))
			if(length(not.found > 0))
			{
				warn(sprintf("%s of %s %s genes not found! [%s]", length(not.found), length(genes), score.name, paste(genes[not.found], collapse=", ")))
			}
			### Grab the counts for the filtered (present and expressed) list of genes, now of the right length.
			found.genes.indices = which(as.character(toupper(rownames(counts))) %in% as.character(toupper(found.genes)))
			
			counts.of.genes = counts[found.genes.indices, ]
			print(dim(counts.of.genes))
			if(verbose){
				info(sprintf("Using genes:"))
				info(paste(found.genes, collapse=", "))
				info(sprintf("Calculating %s score of (using %s genes)", score.name, nrow(counts.of.genes)))
			}
			if(do.norm)
			{
				gene.list = rownames(counts.of.genes)
				controls = get_controls(counts, gene.list)
				counts.of.control.genes = counts[controls,]
			}
			print(dim(counts.of.control.genes))
			mean.col = paste(score.name, "mean", sep="_")
			mean.z.col = paste(score.name, "meanZscore", sep="_")
			info(sprintf("Calculating %s", mean.col))
			scores = data.frame(Matrix::colMeans(counts.of.genes))
			colnames(scores) = mean.col
			sparse = NULL
			if(is(counts.of.genes, "dgCMatrix"))
			{
				warn("Matrix is sparse. Not scaling. Z-scored scores will not be available")
				sparse = T
			}else{
				sparse = F
				centred.counts = t(scale(t(counts.of.genes)))
				scores[, mean.z.col] = colMeans(centred.counts)
			}
			if(do.norm)
			{
				if(verbose){info("Calculated normalised version of mean, and z-score")}
				# calculate normalised score by taking the mean of the markers minus the mean of the controls
				scores = cbind(scores, scores[, mean.col] - Matrix::colMeans(counts.of.control.genes))
				colnames(scores)[ncol(scores)] <- paste(mean.col, "normalised", sep="_")
				if(!sparse){
					centred.counts.bkgd = t(scale(t(counts.of.control.genes)))
					scores[, paste(mean.z.col, "normalised", sep="_")] = scores[, mean.z.col] - colMeans(centred.counts.bkgd)
				}
			}
			if(!is.null(quality.scores)){
				info("Running linear regression against provided cell quality scores")
				y = unlist(scores[, mean.col])
				names(y) = colnames(counts)
				reg = lm(y ~ quality.scores)
				scores[, paste(mean.col, "norm_linreg", sep="_")] <- residuals(reg)
			}
			if(is.null(rval))
			{
				rval = scores
			}else{
				rval = cbind.data.frame(rval, scores)
			}
		}
	}
	return (rval)
}



# write significantly up and down-regulated genes based on the min
# p-value threshold given. Also write the complete table.
write.output <- function(de, de.sig, name_of_population, de.sig.down=NULL)
{
	info(sprintf("Current working dir: %s", getwd()))
	out.table.sig = paste("markers_", name_of_population,".txt",sep="")

	info(sprintf("Writing significant DE genes to: %s", out.table.sig))
	# significant genes are written as markers
	wrote.something = FALSE
	if(!is.null(de.sig))
	{
		write.table(de.sig,
					file=out.table.sig,
					row.names=F,
					col.names=T,
					sep="\t",
					quote=F)
		wrote.something = TRUE
	}else
	{
		warn("Marker table is NULL! (Not writing it obv)")
	}
	
	# write the complete (ranked) table for reference
	out.table.all = paste("all_genes_",name_of_population,".txt",sep="")
	if(!is.null(de))
	{
		info(sprintf("Writing complete set of genes to: %s", out.table.all))
		write.table(de,
					file=out.table.all,
					row.names=F,
					col.names=T,
					sep="\t",
					quote=F)
		wrote.something = TRUE
	}else
	{
		warn("Marker table is NULL! (Not writing it obv)")
	}
	if(wrote.something)
	{
		info("Done writing markers.")
	}else
	{
		warn("Both tables were NULL! Nothing written!")
	}
}


cluster.similarity.matrix <- function(counts, clusters, verbose=T, dm=NULL)
{

	#cor = rcorr(as.matrix(t(counts)))
	#cor.mat = bigcor(as.matrix(counts), method="pearson")
	if(is.null(dm))
	{
		info("Calculating covariance matrix..") 
		cor.mat = cor(as.matrix(counts), method="pearson")
	}else
	{
		info("Using provided distance matrix")
		cor.mat = dm
	}
	
	colnames(cor.mat) = colnames(counts)
	rownames(cor.mat) = colnames(counts)		
	
	if(verbose)
	{
		info("Aggregating covariance matrix..")
	}
	#print(dim(cor.mat))
	#print(length(clusters))
	d = as.data.frame(cor.mat[,])
	if(verbose)
	{	
		info("Aggregating rows..")
	}
	cor.average.clusters <- aggregate(data.frame(d), by=list(clusters), FUN=mean, na.rm=TRUE)
	rownames(cor.average.clusters) = cor.average.clusters$Group.1
	cor.average.clusters$Group.1 = NULL
	
	if(verbose)
	{
		info("Aggregating columns..")
	}
	#print(dim(cor.average.clusters))
	cor.average.clusters <- aggregate(data.frame(t(cor.average.clusters)), by=list(clusters), FUN=mean, na.rm=TRUE)
	rownames(cor.average.clusters) = cor.average.clusters$Group.1
	cor.average.clusters$Group.1 = NULL
	#print(cor.average.clusters)
	return (cor.average.clusters)
}

# cluster.similarity <- function(counts, clusters,
# 					marker.genes=NULL,
# 					verbose=F, 
# 					cor.mat=NULL,
# 					draw.heatmap=F, 
# 					min.cluster.size=0, # if > 0, the function returns the most similar cluster with 
# 					method="average.pairwise.corr", #or marker.genes, or average.corr
# 					n=1)
# {
# 	if(is.null(cor.mat))
# 	{
# 		#info(sprintf("Using %s correlation..", method, gene))
# 		if(verbose)
# 		{
# 			info("Calculating covariance matrix..") 
# 		}
# 		#cor = rcorr(as.matrix(t(counts)))
# 		#cor.mat = bigcor(as.matrix(counts), method="pearson")
# 		cor.mat = cor(as.matrix(counts), method="pearson")
# 		colnames(cor.mat) = colnames(counts)
# 		rownames(cor.mat) = colnames(counts)		
# 	}
# 	if(verbose)
# 	{
# 		info("Aggregating covariance matrix..")
# 	}
# 	#print(dim(cor.mat))
# 	#print(length(clusters))
# 	d = as.data.frame(cor.mat[,])
# 	if(verbose)
# 	{	
# 		info("Aggregating rows..")
# 	}
# 	cor.average.clusters <- aggregate(data.frame(d), by=list(clusters), FUN=mean, na.rm=TRUE)
# 	rownames(cor.average.clusters) = cor.average.clusters$Group.1
# 	cor.average.clusters$Group.1 = NULL
	
# 	if(verbose)
# 	{
# 		info("Aggregating columns..")
# 	}
# 	#print(dim(cor.average.clusters))
# 	print(corner(cor.average.clusters))

# 	cor.average.clusters <- aggregate(data.frame(t(cor.average.clusters)), by=list(clusters), FUN=mean, na.rm=TRUE)
# 	rownames(cor.average.clusters) = cor.average.clusters$Group.1
# 	cor.average.clusters$Group.1 = NULL
# 	#print(cor.average.clusters)

# 	if(draw.heatmap)
# 	{
# 		nmf.options(grid.patch=TRUE)
# 		pdf("Cluster.correlation.pdf"); aheatmap(cor.average.clusters);dev.off()
# 	}
# 	return (cor.average.clusters)
# }


get.most.similar.cluster <- function(counts, 
					clusters, 
					cluster,
					marker.genes=NULL,
					verbose=F, 
					cor.mat=NULL,
					draw.heatmap=F, 
					min.cluster.size=0, # if > 0, the function returns the most similar cluster with 
					method="average.pairwise.corr", #or marker.genes, or average.corr
					n=1)
{

	# similarity by pearson correlation of average expression.
	if(method == "average.corr")
	{	
		counts.average.clusters <- aggregate(t(counts), by=list(clusters), FUN=mean, na.rm=TRUE)
		rownames(counts.average.clusters) = counts.average.clusters$Group.1
		counts.average.clusters$Group.1 = NULL
		counts.average.clusters = t(counts.average.clusters)
		cor.m = cor(counts.average.clusters)
		# info("Correlation matrix:")
		# print(cor.m)
		if(draw.heatmap)
		{
			nmf.options(grid.patch=TRUE)
			pdf("Cluster.correlation.pdf"); aheatmap(cor.m);dev.off()
		}
		#print(cor.m[,cluster])
		if(min.cluster.size > 0)
		{
			for(i in 1: length(unique(clusters)))
			{
				most.sim = names(cor.m[,cluster])[ order(cor.m[,cluster], decreasing=T)[1+i]]
				y = length(which(clusters==most.sim))
				if(y > min.cluster.size)
				{
					return ( most.sim)
				}
			}
			error(sprintf("No cluster found more than %s cells!", min.cluster.size))
			return(NULL)
		}else
		{
			most.sim = names(cor.m[,cluster])[ order(cor.m[,cluster], decreasing=T)[2]]
			return(most.sim)
		}
	}else
	{	# similarity by average pairwise correlations between cells
		if(method=="average.pairwise.corr")
		{
			if(is.null(cor.mat))
			{
				#info(sprintf("Using %s correlation..", method, gene))
				if(verbose)
				{
					info("Calculating covariance matrix..") 
				}
				#cor = rcorr(as.matrix(t(counts)))
				#cor.mat = bigcor(as.matrix(counts), method="pearson")
				cor.mat = cor(as.matrix(counts), method="pearson")
				colnames(cor.mat) = colnames(counts)
				rownames(cor.mat) = colnames(counts)		
			}
			if(verbose)
			{
				info("Aggregating covariance matrix..")
			}
			#print(dim(cor.mat))
			#print(length(clusters))
			d = as.data.frame(cor.mat[,])
			if(verbose)
			{	
				info("Aggregating rows..")
			}
			cor.average.clusters <- aggregate(data.frame(d), by=list(clusters), FUN=mean, na.rm=TRUE)
			rownames(cor.average.clusters) = cor.average.clusters$Group.1
			cor.average.clusters$Group.1 = NULL
			
			if(verbose)
			{
				info("Aggregating columns..")
			}
			#print(dim(cor.average.clusters))
			print(corner(cor.average.clusters))

			cor.average.clusters <- aggregate(data.frame(t(cor.average.clusters)), by=list(clusters), FUN=mean, na.rm=TRUE)
			rownames(cor.average.clusters) = cor.average.clusters$Group.1
			cor.average.clusters$Group.1 = NULL
			#print(cor.average.clusters)

			if(draw.heatmap)
			{
				nmf.options(grid.patch=TRUE)
				pdf("Cluster.correlation.pdf"); aheatmap(cor.average.clusters);dev.off()
			}
			cors = cor.average.clusters[, cluster]
			names(cors) = colnames(cor.average.clusters)
			#print(cors)
			
			if(min.cluster.size > 0)
			{
				for(i in 1: length(unique(clusters)))
				{
					most.sim = names(cors)[ order(cors, decreasing=T)[i]]
					y = length(which(clusters==most.sim))
					if(y > min.cluster.size & most.sim != cluster)
					{
						return ( most.sim)
					}
				}
				error(sprintf("No cluster found more than %s cells!", min.cluster.size))
				return(NULL)
			}else
			{
				most.sim = names(cors)[ order(cors, decreasing=T)[2]]
				if(most.sim == cluster)
				{
					most.sim = names(cors)[ order(cors, decreasing=T)[1]]
				}
			}
			
			return(most.sim)
		}else{
			# given a set of markers, use those markers to find the most similar cluster, that is,
			# return the cluster with the highest average expression of those markers.
			if(is.null(marker.genes))
			{
				error("Cannot assess similarity via marker.genes when marker.genes is NULL!")
				return (NULL)
			}
			if(verbose)
			{
				info("Aggregating columns..")
			}
			counts.markers = counts[rownames(counts) %in% marker.genes, ]
			counts.average.clusters <- aggregate(t(counts.markers), by=list(clusters), FUN=mean, na.rm=TRUE)
			rownames(counts.average.clusters) = counts.average.clusters$Group.1
			counts.average.clusters$Group.1 = NULL
			counts.average.clusters = t(counts.average.clusters)
			average.marker.expr = colSums(counts.average.clusters)
			print(average.marker.expr)

			if(min.cluster.size > 0)
			{
				for(i in 1: length(unique(clusters)))
				{
					
					most.sim = names(average.marker.expr)[ order(average.marker.expr, decreasing=T)[i]]
					y = length(which(clusters==most.sim))

					cat(sprintf("Trying rank %i: %s (Size=%s) \n", i, most.sim,y))
					
					if(y > min.cluster.size & most.sim != cluster)
					{
						return ( most.sim)
					}
				}
				error(sprintf("No cluster found more than %s cells!", min.cluster.size))
				return(NULL)
			}else
			{
				most.sim = names(average.marker.expr)[ order(average.marker.expr, decreasing=T)[1]]
				if(most.sim == cluster)
				{
					most.sim = names(average.marker.expr)[ order(average.marker.expr, decreasing=T)[]]
				}
			}
			return (most.sim)
		}
	}
}

plot.markers <- function(seurat.obj, 
							de.sig,
							clusters=NULL,
							plot_n =20,
							id="DBclust.ident",
							secondary.id="orig.ident",
							feature.palette = "OrRd",
							violin.palette = "Spectral",
							brewer.reverse = T,
							sam.r.colors = T)
{
	if(!is.null(seurat.obj))
	{
			
		# violin plots:
		info("Generating violin plots")
		n_facs_groups = length(unique(unlist(fetch.data(seurat.obj, secondary.id))))
		info(sprintf("Secondary ID: %s. There are %s values", secondary.id, n_facs_groups))
		pdf(sprintf("Violin_by_%s.pdf", secondary.id))
		
		if(!is.null(clusters))
		{
			n_clusters = length(unique(clusters))
		}else{
			n_clusters = length(unique(seurat.obj@ident))
		}
		
		
		for(k in 1:plot_n){
			top_marker = rownames(de.sig)[k]
			if(!is.na(top_marker)){
				# do.ret gets us back the ggplot object, which can be 
				# modified to slant the axis labels.
				x = vlnPlot(seurat.obj, top_marker, 
											group.by = secondary.id,
											size.x.use=8, 
											size.y.use=8, 
											size.title.use=10, 
											cols.use=colorRampPalette(brewer.pal(n_facs_groups, violin.palette))(n_facs_groups),
											do.ret = T)[[1]] + theme(axis.text.x = element_text(angle=45, vjust=1, hjust=1))
				print(x)				
			}
		}
		dev.off()
		pdf("Violin_by_cluster.pdf")
		for(k in 1:plot_n){
			top_marker = rownames(de.sig)[k]
			if(!is.na(top_marker)){
				x = vlnPlot(seurat.obj, top_marker, 
											group.by = id,
											size.x.use=8, 
											size.y.use=8, 
											size.title.use=10, 
											cols.use=colorRampPalette(brewer.pal(n_clusters, violin.palette))(n_clusters),
											do.ret = T)[[1]] + theme(axis.text.x = element_text(angle=45, vjust=1, hjust=1))
				print(x)
			}else
			{
				cat(sprintf("WARN: Marker %i is Nan. Can only plot the top %i! \n", k, k-1))
				plot_n = k-1
				break
			}
		}
		dev.off()

		# tSNE and feature plot overlays:
		info("Generating feature plots..")
		pdf("feature_plot.pdf", width=20, height=20)
		if(sam.r.colors)
		{
			colors = rev(get.hmap.col())
		}else{
			if(brewer.reverse)
			{
				colors = rev(colorRampPalette(brewer.pal(9,feature.palette))(20))
			}else
			{
				colors = colorRampPalette(brewer.pal(9,feature.palette))(20)
			}
		}

		#feature.plot(seurat.obj, rownames(de.sig)[1:plot_n], cols.use=colors)
		feature.plot.scale(seurat.obj, rownames(de.sig)[1:plot_n])
		# tsne.plot(seurat.obj)
		# seurat.obj = set.all.ident(seurat.obj, secondary.id)
		# tsne.plot(seurat.obj)
		dev.off()


	}else
	{
		info("WARN: Seurat object is null, cannot generate marker plots!")
	}
}
